# ── API Keys ──────────────────────────────────────────────────────────────
GROQ_API_KEY=
OPENAI_API_KEY=
COHERE_API_KEY=
TAVILY_API_KEY=

# ── LLM Configuration ────────────────────────────────────────────────────
# Select which LLM backend to use: "groq" (default) or "openai"
# LLM_PROVIDER=groq

# GROQ_MODEL=llama-3.3-70b-versatile
# GROQ_TEMPERATURE=0.0
# GROQ_MAX_TOKENS=4096
# GROQ_GRADING_MODEL=              # If set, use a separate model for grading

# OPENAI_MODEL=gpt-4o-mini

# ── ChromaDB ──────────────────────────────────────────────────────────────
CHROMA_PERSIST_DIR=./chroma_data
CHROMA_COLLECTION_NAME=eu_ai_act
ANONYMIZED_TELEMETRY=False          # Suppress ChromaDB posthog telemetry errors

# ── Retrieval ─────────────────────────────────────────────────────────────
TOP_K_RETRIEVAL=25
TOP_K_FINAL=5
PRIMARY_SOURCE_BOOST=1.2

# ── Latency ───────────────────────────────────────────────────────────────
LATENCY_BUDGET_SECONDS=10.0
MAX_RETRIES=3
# ── Rate Limiting ─────────────────────────────────────────────────────
# RATE_LIMIT_RPM=30.0
# RATE_LIMIT_BURST=10

# ── Response Cache ────────────────────────────────────────────────────
# CACHE_MAX_SIZE=128
# CACHE_TTL_SECONDS=300
# CACHE_SIMILARITY_THRESHOLD=0.90
# ── Langfuse (optional) ───────────────────────────────────────────────────
# LANGFUSE_SECRET_KEY=
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_HOST=https://cloud.langfuse.com

# ── OpenTelemetry ─────────────────────────────────────────────────────────
OTEL_SERVICE_NAME=scra-agent
OTEL_EXPORTER_ENDPOINT=

# ── Logging ───────────────────────────────────────────────────────────────
# LOG_FORMAT=text                   # "text" or "json"
# LOG_LEVEL=INFO

# ── Testing ───────────────────────────────────────────────────────────────
RUN_LIVE_TESTS=0
